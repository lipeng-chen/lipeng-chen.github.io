---
title: "TossNet: Learning to Accurately Measure and Predict Robot Throwing of Arbitrary Objects in Real Time With Proprioceptive Sensing"
authors: |
  **Lipeng Chen**, Weifeng Lu, Kun Zhang, *et al.*  
venue: "IEEE Transactions on Robotics"
year: 2024
category: Grasping, Manipulation
# pages: "3232-3251"
doi: "10.1109/TRO.2024.3416009"
pdf: "2024_tro_tossing.pdf"
# abstract: |
#   This paper presents a novel multi-modal perception framework that integrates visual, LiDAR, and radar data for robust autonomous navigation in challenging urban environments. 
  
#   **Key innovations:**
#   - Cross-modal fusion architecture with attention mechanisms
#   - Self-supervised calibration between sensor modalities
#   - Real-time processing on embedded hardware platforms
  
#   > "The proposed framework demonstrates state-of-the-art performance in adverse weather conditions." - Reviewer #1
# code: "https://github.com/lipeng-chen/multi-modal-perception"
video: "https://youtu.be/y_Bz9debQyg"
# data: "https://zenodo.org/record/1234567"
# slides: "https://slides.com/lipengchen/multi-modal"
# poster: "https://example.com/poster.pdf"
# demo: "https://example.com/live-demo"
bibtex: |
  @article{chen2024tossnet,
    title={TossNet: Learning to Accurately Measure and Predict Robot Throwing of Arbitrary Objects in Real Time With Proprioceptive Sensing},
    author={Chen, Lipeng and Lu, Weifeng and Zhang, Kun and Zhang, Yizheng and Zhao, Longfei and Zheng, Yu},
    journal={IEEE Transactions on Robotics},
    year={2024},
    publisher={IEEE}
  }
# project_page: "https://multi-modal.sjtu.edu.cn"
# preprint: "https://arxiv.org/abs/2401.12345"
---